# Environment Variables for Video LLM Evaluation
# Copy to .env: cp env.template .env

# === Quick Setup Guide ===
# 1. Gemini: Add GEMINI_API_KEY (cloud API)
# 2. GPT-4o: Add OPENAI_API_KEY (cloud API)
# 3. Qwen: Install Ollama + choose model type:
#    - Install: https://ollama.com
#    - Local (FREE): ollama pull qwen2.5-vl (no API key!)
#    - Cloud: ollama pull qwen3-vl-cloud + add OLLAMA_API_KEY
#    - Verify: ollama list
# 4. Copy this file: cp env.template .env

# === Video LLM API Keys ===

# Gemini (Google AI)
# Get key: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=

# OpenAI GPT-4o
# Get key: https://platform.openai.com/api-keys
OPENAI_API_KEY=

# === Qwen VL via Ollama ===
# Install Ollama: https://ollama.com

# Option 1: Local Models (FREE, no API key needed)
# Pull model: ollama pull qwen2.5-vl
# Models WITHOUT -cloud suffix run locally on your machine
# OLLAMA_BASE_URL=http://localhost:11434  # (default)

# Option 2: Cloud Models (API key required)
# For models WITH -cloud suffix (e.g., qwen3-vl-cloud, qwen3-vl:235b-cloud)
# These run on Ollama's servers via your local Ollama client
# Get API key: https://ollama.com/settings/keys
# Or sign in: ollama signin
OLLAMA_API_KEY=

# Cloud models still use local Ollama (it proxies to cloud)
# OLLAMA_BASE_URL=http://localhost:11434  # (default, use this for both local and cloud)

# === Data Collection (optional) ===
# Twitter API for tweet data: https://developer.twitter.com/
# TWITTER_BEARER_TOKEN=

# Custom video storage path (default: data/videos/)
# VIDEO_DOWNLOAD_PATH=

# === Database (optional) ===
# PostgreSQL connection (default: postgresql://localhost/video_llm_eval)
# DATABASE_URL=postgresql://username:password@localhost:5432/video_llm_eval
